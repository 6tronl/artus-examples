{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28b4af-8306-4bd9-9c47-18a8aceb049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylabel import importer\n",
    "import yaml\n",
    "\n",
    "def split_coco(min_nb_occurences, features=None):\n",
    "    ''' Split a coco file into a train, test and (optional) validation coco files.\n",
    "    # Inputs:\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "min_nb_occurences = 50\n",
    "\n",
    "features = ['species']\n",
    "\n",
    "for feature in features:\n",
    "    coco_path = f'/home/justine/fmr/tiles_1500_overlap25/coco/coco_{feature}.json'\n",
    "\n",
    "    dataset = importer.ImportCoco(path=coco_path, name=\"dataset\")\n",
    "    dataset_train = importer.ImportCoco(path=coco_path, name=\"trainset\")\n",
    "    dataset_val = importer.ImportCoco(path=coco_path, name=\"valset\")\n",
    "    dataset_test = importer.ImportCoco(path=coco_path, name=\"testset\")\n",
    "\n",
    "    #remove tiles without annotations\n",
    "    ind_images_without_annot = dataset.df.loc[dataset.df['cat_name']==''].index\n",
    "    dataset.df.drop(index=ind_images_without_annot, inplace=True)\n",
    "\n",
    "    #avoid duplicates names\n",
    "    if feature=='species':\n",
    "        dataset.df.loc[dataset.df['cat_name'] == 'Lutea', 'cat_name'] = \"lutea\"\n",
    "        dataset.df.loc[dataset.df['cat_name'] == 'Muricata 1', 'cat_name'] = \"muricata\"\n",
    "\n",
    "\n",
    "    #remove classes that does not reach the minimum number of occurences/class\n",
    "    grouped_by_class = dataset.df.groupby(by='cat_name', axis=0).count()\n",
    "    under_represented_classes = grouped_by_class[grouped_by_class['img_folder'] < min_nb_occurences].index\n",
    "    deleted_classes=list(under_represented_classes.values)\n",
    "    index_to_remove = dataset.df[dataset.df.cat_name.isin(deleted_classes)].index\n",
    "    dataset.df.drop(index=index_to_remove, inplace=True)\n",
    "\n",
    "    print(f\"Number of images after removing classes: {dataset.analyze.num_images}\")\n",
    "    print(f\"Number of classes after removing classes: {dataset.analyze.num_classes}\")\n",
    "    print(f\"Classes after removing classes:{dataset.analyze.classes}\")\n",
    "    print(f\"Class counts after removing classes:\\n{dataset.analyze.class_counts}\")\n",
    "\n",
    "    #split the dataset\n",
    "    dataset.splitter.StratifiedGroupShuffleSplit(train_pct=.8, val_pct=.1, test_pct=.1, batch_size=2)\n",
    "    dataset.analyze.ShowClassSplits()\n",
    "\n",
    "    df_train = dataset.df.query(\"split == 'train'\")\n",
    "    df_val = dataset.df.query(\"split == 'val'\")\n",
    "    df_test = dataset.df.query(\"split == 'test'\")\n",
    "\n",
    "    # filter images that are moved in the other datasets\n",
    "    dataset_train.df = dataset_train.df[dataset_train.df.img_filename.isin(df_train[\"img_filename\"])].reset_index()\n",
    "    # filter categories that have been deleted\n",
    "    dataset_train.df = dataset_train.df[dataset_train.df.cat_name.isin(df_train[\"cat_name\"])].reset_index()\n",
    "\n",
    "    dataset_val.df = dataset_val.df[dataset_val.df.img_filename.isin(df_val[\"img_filename\"])].reset_index()\n",
    "    dataset_val.df = dataset_val.df[dataset_val.df.cat_name.isin(df_val[\"cat_name\"])].reset_index()\n",
    "\n",
    "    dataset_test.df = dataset_test.df[dataset_test.df.img_filename.isin(df_test[\"img_filename\"])].reset_index()\n",
    "    dataset_test.df = dataset_test.df[dataset_test.df.cat_name.isin(df_test[\"cat_name\"])].reset_index()\n",
    "\n",
    "    # change dataset names\n",
    "    dataset_train.name = f'coco_train80_{feature}'\n",
    "    dataset_val.name = f'coco_val10_{feature}'\n",
    "    dataset_test.name = f'coco_test10_{feature}'\n",
    "    # export the datasets to coco format\n",
    "    dataset_train.export.ExportToCoco()\n",
    "    dataset_val.export.ExportToCoco()\n",
    "    dataset_test.export.ExportToCoco()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9983856-245e-436f-b59a-ce52444d934a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36627ad5-f27b-44fa-bc1e-58cf4867181a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f5a51b4-226a-4207-b12c-743c0ead108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylabel import importer, dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def rm_min_classes(dataset, min_nb_occurrences):\n",
    "    '''remove classes that does not reach the minimum number of occurences/class\n",
    "    #Inputs :\n",
    "    - dataset : a coco file read with importer.ImportCoco() from pylabel\n",
    "    - min_nb_occurrences : an integer that is the minimum number of occurrences of a class to be kept in the dataset (remove under representated classes)\n",
    "    # Output : \n",
    "    - the same dataset with classes that have less than the minimum number of occurrences removed.\n",
    "    '''\n",
    "    grouped_by_class = dataset.df.groupby(by='cat_name', axis=0).count()\n",
    "    under_represented_classes = grouped_by_class[grouped_by_class['img_folder'] < min_nb_occurrences].index\n",
    "    deleted_classes=list(under_represented_classes.values)\n",
    "    index_to_remove = dataset.df[dataset.df.cat_name.isin(deleted_classes)].index\n",
    "    dataset.df.drop(index=index_to_remove, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def rm_tiles_without_annot(dataset):\n",
    "    '''remove tiles without annotations\n",
    "    #Input:\n",
    "    - dataset : a coco file read with importer.ImportCoco() from pylabel\n",
    "    # Output:\n",
    "    - the same dataset with rows that do not contains any info in the 'cat_name' column removed.\n",
    "    '''\n",
    "    ind_images_without_annot = dataset.df.loc[dataset.df['cat_name']==''].index\n",
    "    dataset.df.drop(index=ind_images_without_annot, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class COCOStats():\n",
    "    ''' A class to explore the basic stats of a coco file'''\n",
    "    def __init__(self, coco_path, min_nb_occurrences=None):\n",
    "        self.dataset = self.process_coco(coco_path, min_nb_occurrences)\n",
    "\n",
    "    def process_coco(self, coco_path, min_nb_occurrences):\n",
    "        ''' remove the samples without annotations and removed underrepresetned classes if needed'''        \n",
    "        dataset = importer.ImportCoco(path=coco_path, name=\"dataset\")  \n",
    "        dataset = rm_tiles_without_annot(dataset)\n",
    "        if min_nb_occurrences:\n",
    "            dataset = rm_min_classes(dataset, min_nb_occurrences)\n",
    "        return dataset\n",
    "    \n",
    "    def get_class_stats(self):\n",
    "        '''print the number of occurrences per classes'''\n",
    "        print(f\"Classes:{self.dataset.analyze.classes}\")\n",
    "        print(f\"Number of classes: {self.dataset.analyze.num_classes}\")\n",
    "        print(f\"Class counts:\\n{self.dataset.analyze.class_counts}\")\n",
    "        \n",
    "    def get_nb_images(self):\n",
    "        print(f\"Number of images: {self.dataset.analyze.num_images}\")\n",
    "    \n",
    "    def export_stats(self, export_path):\n",
    "        ''' Export the stats in csv format at the export_path'''\n",
    "        self.dataset.analyze.class_counts.to_csv(export_path)\n",
    "\n",
    "\n",
    "class COCOSplitter(COCOStats):\n",
    "    ''' Split a coco file into a train, test and (optional) validation coco files. Proportions of class annotations are kept into the splits.\n",
    "    # Inputs:\n",
    "    - coco_path : a path to a coco file\n",
    "    - export_dir : a directory where the splits of the coco files will be exported\n",
    "    - coco_train_name : the name of the file with the annotations for training\n",
    "    - coco_test_name : the name of the file with the annotations for testing\n",
    "    - coco_val_name : the name of the file with the annotations for validation\n",
    "    - min_nb_occurrences : an integer that is the minimum number of occurrences of a class to be kept in the dataset (remove under representated classes)\n",
    "    - train_pct : the fraction (float) of annotations that will go into the train coco file\n",
    "    - val_pct : the fraction (float) of annotations that will go into the validation coco file\n",
    "    - test_pct : the fraction (float) of annotations that will go into the test coco file\n",
    "    - batch_size\n",
    "    # Outputs:\n",
    "    Splits of the coco files are exported in COCO format in the export_dir mentionned.\n",
    "    ''''\n",
    "    def __init__(self, coco_path, export_dir, coco_train_name, coco_test_name, coco_val_name, min_nb_occurrences=None, train_pct=.8, val_pct=.1, test_pct=.1, batch_size=8):\n",
    "        self.dataset = self.process_coco(coco_path, min_nb_occurrences)\n",
    "        self.export_dir = export_dir\n",
    "        self.coco_train_name = coco_train_name\n",
    "        self.coco_test_name = coco_test_name\n",
    "        self.coco_val_name = coco_val_name\n",
    "        \n",
    "        \n",
    "    def create_train_test_val_datasets(self):\n",
    "        dataset_train = importer.ImportCoco(path=coco_path, name=\"trainset\")\n",
    "        dataset_val = importer.ImportCoco(path=coco_path, name=\"valset\")\n",
    "        dataset_test = importer.ImportCoco(path=coco_path, name=\"testset\")\n",
    "        return dataset_train, dataset_val, dataset_test\n",
    "    \n",
    "    def split_coco(self):\n",
    "        self.dataset.splitter.StratifiedGroupShuffleSplit(train_pct=.8, val_pct=.1, test_pct=.1, batch_size=2)\n",
    "        \n",
    "        self.dataset.analyze.ShowClassSplits()\n",
    "\n",
    "        df_train = self.dataset.df.query(\"split == 'train'\")\n",
    "        df_val = self.dataset.df.query(\"split == 'val'\")\n",
    "        df_test = self.dataset.df.query(\"split == 'test'\")\n",
    "\n",
    "        df_train = dataset.Dataset(df_train)\n",
    "        df_val = dataset.Dataset(df_val)\n",
    "        df_test = dataset.Dataset(df_test)\n",
    "        \n",
    "        df_train.export.ExportToCoco(output_path=os.path.join(self.export_dir, self.coco_train_name, '.json'))\n",
    "        df_val.export.ExportToCoco(output_path=os.path.join(self.export_dir, self.coco_val_name, '.json'))\n",
    "        df_test.export.ExportToCoco(output_path=os.path.join(self.export_dir, self.coco_test_name, '.json'))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4cf1b7b-068f-4c34-adcc-acf7d090c79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitter = COCOSplitter(coco_path='/home/justine/fmr/tiles_1500_overlap25/coco/coco_species.json', min_nb_occurrences=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "afa3f071-95f9-4111-b716-8c60c5e0f58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_coco\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[98], line 66\u001b[0m, in \u001b[0;36mCOCOSplitter.split_coco\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_coco\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Split a coco file into a train, test and (optional) validation coco files.'''\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStratifiedGroupShuffleSplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39manalyze\u001b[38;5;241m.\u001b[39mShowClassSplits()\n\u001b[1;32m     70\u001b[0m     df_train \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pylabel/splitter.py:81\u001b[0m, in \u001b[0;36mSplit.StratifiedGroupShuffleSplit\u001b[0;34m(self, train_pct, test_pct, val_pct, weight, group_col, cat_col, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m         df_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(pd\u001b[38;5;241m.\u001b[39mDataFrame(group), ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "splitter.split_coco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b453562-8dc3-4228-b02d-8b09422e0bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
